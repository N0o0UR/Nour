<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>tidymodels | HOME</title>
    <link>/category/tidymodels/</link>
      <atom:link href="/category/tidymodels/index.xml" rel="self" type="application/rss+xml" />
    <description>tidymodels</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Thu, 22 Jul 2021 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/media/icon_hua2ec155b4296a9c9791d015323e16eb5_11927_512x512_fill_lanczos_center_2.png</url>
      <title>tidymodels</title>
      <link>/category/tidymodels/</link>
    </image>
    
    <item>
      <title>A03 Resampling Methods</title>
      <link>/post/a03-resampling-methods/</link>
      <pubDate>Thu, 22 Jul 2021 00:00:00 +0000</pubDate>
      <guid>/post/a03-resampling-methods/</guid>
      <description>
&lt;script src=&#34;/post/a03-resampling-methods/index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;the-goal&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The Goal&lt;/h3&gt;
&lt;p&gt;The goal behind this study is to discuss two of the most commonly used resampling methods, cross-validation and the bootstrap and we would apply both resampling methods on linear and logistic regression models.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;first-for-logistic-regression-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;First For Logistic Regression Model:&lt;/h2&gt;
&lt;div id=&#34;the-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The data&lt;/h3&gt;
&lt;p&gt;The data used in this study was obtained from UCI website and we specifically used the Bank-full.csv dataset.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;splitting-the-data-to-training-and-testing-splits&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Splitting the data to training and testing splits&lt;/h3&gt;
&lt;p&gt;In this step we are going to split the data so that 3/4 of the data would be assigned for training and the remaining 1/4 of the data would be assigned for testing.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;create-the-logistic-regression-model&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Create the logistic regression model&lt;/h3&gt;
&lt;p&gt;Creating the logistic regression model that will be used to identify whether a customer will subscribe to a term deposit or not.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;creating-the-recipe&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Creating the recipe&lt;/h3&gt;
&lt;p&gt;Creating the suitable recipe to apply feature engineering to our data&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;create-workflow&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Create workflow&lt;/h3&gt;
&lt;p&gt;Create a workflow that combine the model and the recipe.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;fit-the-model&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Fit the model&lt;/h3&gt;
&lt;p&gt;Train and fitting the model using the training split of the data.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 35 x 5
##    term              estimate std.error statistic  p.value
##    &amp;lt;chr&amp;gt;                &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;
##  1 (Intercept)         -1.65     0.126     -13.1  3.88e-39
##  2 duration             1.06     0.0189     56.3  0       
##  3 campaign            -0.272    0.0358     -7.60 2.94e-14
##  4 job_blue.collar     -0.368    0.0833     -4.41 1.01e- 5
##  5 job_entrepreneur    -0.367    0.143      -2.57 1.01e- 2
##  6 job_housemaid       -0.441    0.150      -2.95 3.20e- 3
##  7 job_management      -0.243    0.0838     -2.90 3.72e- 3
##  8 job_retired          0.166    0.0997      1.67 9.57e- 2
##  9 job_self.employed   -0.330    0.128      -2.57 1.03e- 2
## 10 job_services        -0.242    0.0971     -2.49 1.27e- 2
## 11 job_student          0.521    0.119       4.37 1.23e- 5
## 12 job_technician      -0.183    0.0794     -2.31 2.11e- 2
## # ... with 23 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;make-predictions-for-training-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Make predictions for training data&lt;/h3&gt;
&lt;p&gt;Using the trained model for prediction on the training data.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 33,907 x 11
##    .pred_class y     job          education housing loan  contact month duration
##    &amp;lt;fct&amp;gt;       &amp;lt;fct&amp;gt; &amp;lt;fct&amp;gt;        &amp;lt;fct&amp;gt;     &amp;lt;fct&amp;gt;   &amp;lt;fct&amp;gt; &amp;lt;fct&amp;gt;   &amp;lt;fct&amp;gt;    &amp;lt;int&amp;gt;
##  1 no          no    management   tertiary  yes     no    unknown may        261
##  2 no          no    entrepreneur secondary yes     yes   unknown may         76
##  3 no          no    blue-collar  unknown   yes     no    unknown may         92
##  4 no          no    unknown      unknown   no      no    unknown may        198
##  5 no          no    management   tertiary  yes     no    unknown may        139
##  6 no          no    technician   secondary yes     no    unknown may         55
##  7 no          no    admin.       secondary yes     no    unknown may        137
##  8 no          no    technician   secondary yes     no    unknown may        517
##  9 no          no    technician   unknown   yes     no    unknown may         71
## 10 no          no    services     secondary yes     no    unknown may        174
## # ... with 33,897 more rows, and 2 more variables: campaign &amp;lt;int&amp;gt;,
## #   poutcome &amp;lt;fct&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;evaluate-performance-on-tarining-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Evaluate performance on tarining data&lt;/h3&gt;
&lt;p&gt;Evaluate the performance of the model on the training data.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;##           Truth
## Prediction    no   yes
##        no  29193  2595
##        yes   748  1371&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 x 3
##   .metric  .estimator .estimate
##   &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt;
## 1 accuracy binary         0.901
## 2 sens     binary         0.975
## 3 spec     binary         0.346&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;make-predictions-for-testing-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Make predictions for testing data&lt;/h3&gt;
&lt;p&gt;Using the trained model for prediction on the testing data.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 11,304 x 11
##    .pred_class y     job          education housing loan  contact month duration
##    &amp;lt;fct&amp;gt;       &amp;lt;fct&amp;gt; &amp;lt;fct&amp;gt;        &amp;lt;fct&amp;gt;     &amp;lt;fct&amp;gt;   &amp;lt;fct&amp;gt; &amp;lt;fct&amp;gt;   &amp;lt;fct&amp;gt;    &amp;lt;int&amp;gt;
##  1 no          no    technician   secondary yes     no    unknown may        151
##  2 no          no    management   tertiary  yes     yes   unknown may        217
##  3 no          no    entrepreneur tertiary  yes     no    unknown may        380
##  4 no          no    retired      primary   yes     no    unknown may         50
##  5 no          no    admin.       secondary yes     no    unknown may        222
##  6 no          no    retired      primary   yes     no    unknown may        353
##  7 no          no    admin.       unknown   yes     no    unknown may         98
##  8 no          no    blue-collar  primary   yes     no    unknown may         38
##  9 no          no    retired      primary   yes     no    unknown may        219
## 10 no          no    technician   secondary yes     yes   unknown may        348
## # ... with 11,294 more rows, and 2 more variables: campaign &amp;lt;int&amp;gt;,
## #   poutcome &amp;lt;fct&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;evaluate-performance-on-testing-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Evaluate performance on testing data&lt;/h3&gt;
&lt;p&gt;Evaluate the performance of the model on the testing data.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;##           Truth
## Prediction   no  yes
##        no  9754  875
##        yes  227  448&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 x 3
##   .metric  .estimator .estimate
##   &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt;
## 1 accuracy binary         0.903
## 2 sens     binary         0.977
## 3 spec     binary         0.339&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;apply-cross-validation-method-for-model-evaluation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Apply Cross Validation method for model evaluation&lt;/h2&gt;
&lt;p&gt;We will use the cross-validation resampling method to evaluate the performance of our logestic regression model.&lt;/p&gt;
&lt;div id=&#34;split-data-into-folds&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Split data into folds&lt;/h3&gt;
&lt;p&gt;The train data is split-ted into 5 folds&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;fit-resamples&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Fit resamples&lt;/h3&gt;
&lt;p&gt;Fit the folds into the workflow.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;collect-cv-metrics&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Collect CV metrics&lt;/h3&gt;
&lt;p&gt;Show the metrics resulted from Cross-Validation process&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2 x 6
##   .metric  .estimator  mean     n std_err .config             
##   &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;      &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;               
## 1 accuracy binary     0.902     5 0.00165 Preprocessor1_Model1
## 2 roc_auc  binary     0.904     5 0.00174 Preprocessor1_Model1&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;The accuracy associated with the model using the training data is 90.1%, that associated with the model using the testing data is 90.3% and that associated with the model using cross validation resampling method is 90.1%. The accuracy in the testing data is quite good and it is slightly better than the accuracy in the training data which indicates that our model is not exposed to overfitting on the training data, also the accuracy resulted from the testing data is comparable with the accuracy we got from cross-validation resampling method that indicates that our model is working properly.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;applying-bootstrap-resampling-method&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Applying Bootstrap resampling method&lt;/h2&gt;
&lt;p&gt;In this part we are estimating the accuracy of a Logestic Regression Model through the bootstrap approach which can be used to assess the variability of the coefficient estimates (Betas) and predictions from a statistical learning method.&lt;/p&gt;
&lt;p&gt;The standard error reflects the variability between the estimates we would obtain if we repeatedly took samples from the population. The standard error associated with the coefficients of both the model and that obtained through bootstrapping are shown below:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;##        (Intercept)     jobblue-collar    jobentrepreneur       jobhousemaid 
##       -2.416485382       -0.346072166       -0.413788618       -0.538843667 
##      jobmanagement         jobretired   jobself-employed        jobservices 
##       -0.189089703        0.196164320       -0.311713723       -0.236414425 
##         jobstudent      jobtechnician      jobunemployed         jobunknown 
##        0.511192792       -0.173019378       -0.177429381       -0.361506746 
## educationsecondary  educationtertiary   educationunknown         housingyes 
##        0.203955264        0.436149134        0.269835962       -0.700007468 
##            loanyes   contacttelephone     contactunknown           monthaug 
##       -0.444875217       -0.175980434       -1.605880094       -0.763099074 
##           monthdec           monthfeb           monthjan           monthjul 
##        0.646688881       -0.251511233       -1.163911847       -0.843156031 
##           monthjun           monthmar           monthmay           monthnov 
##        0.366545869        1.553360619       -0.425837991       -0.874011401 
##           monthoct           monthsep           duration           campaign 
##        0.888103673        0.811484702        0.004190172       -0.086589973 
##      poutcomeother    poutcomesuccess    poutcomeunknown 
##        0.233821843        2.303692088       -0.078536962&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                        Estimate   Std. Error    z value      Pr(&amp;gt;|z|)
## (Intercept)        -2.416485382 1.113856e-01 -21.694773 2.298578e-104
## jobblue-collar     -0.346072166 7.226905e-02  -4.788664  1.678955e-06
## jobentrepreneur    -0.413788618 1.249918e-01  -3.310525  9.312098e-04
## jobhousemaid       -0.538843667 1.354648e-01  -3.977740  6.957349e-05
## jobmanagement      -0.189089703 7.293692e-02  -2.592510  9.527837e-03
## jobretired          0.196164320 8.618864e-02   2.275988  2.284672e-02
## jobself-employed   -0.311713723 1.114374e-01  -2.797210  5.154603e-03
## jobservices        -0.236414425 8.390921e-02  -2.817503  4.839869e-03
## jobstudent          0.511192792 1.044029e-01   4.896346  9.763496e-07
## jobtechnician      -0.173019378 6.880062e-02  -2.514794  1.191020e-02
## jobunemployed      -0.177429381 1.114466e-01  -1.592058  1.113717e-01
## jobunknown         -0.361506746 2.329359e-01  -1.551958  1.206723e-01
## educationsecondary  0.203955264 6.411055e-02   3.181306  1.466128e-03
## educationtertiary   0.436149134 7.395298e-02   5.897654  3.687051e-09
## educationunknown    0.269835962 1.035801e-01   2.605095  9.184878e-03
## housingyes         -0.700007468 4.329460e-02 -16.168472  8.415943e-59
## loanyes            -0.444875217 5.967071e-02  -7.455504  8.952482e-14
## contacttelephone   -0.175980434 7.410680e-02  -2.374687  1.756384e-02
## contactunknown     -1.605880094 7.237608e-02 -22.187993 4.485657e-109
## monthaug           -0.763099074 7.747181e-02  -9.850022  6.852875e-23
## monthdec            0.646688881 1.757141e-01   3.680347  2.329164e-04
## monthfeb           -0.251511233 8.412492e-02  -2.989735  2.792195e-03
## monthjan           -1.163911847 1.196732e-01  -9.725755  2.341610e-22
## monthjul           -0.843156031 7.706815e-02 -10.940395  7.387702e-28
## monthjun            0.366545869 9.019358e-02   4.063991  4.824078e-05
## monthmar            1.553360619 1.187454e-01  13.081435  4.204289e-39
## monthmay           -0.425837991 7.108191e-02  -5.990807  2.088027e-09
## monthnov           -0.874011401 8.371180e-02 -10.440719  1.615814e-25
## monthoct            0.888103673 1.076217e-01   8.252090  1.556480e-16
## monthsep            0.811484702 1.180207e-01   6.875780  6.165138e-12
## duration            0.004190172 6.442787e-05  65.036632  0.000000e+00
## campaign           -0.086589973 1.003337e-02  -8.630197  6.124664e-18
## poutcomeother       0.233821843 8.916180e-02   2.622444  8.730153e-03
## poutcomesuccess     2.303692088 7.959003e-02  28.944480 3.293120e-184
## poutcomeunknown    -0.078536962 5.731654e-02  -1.370232  1.706144e-01&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## ORDINARY NONPARAMETRIC BOOTSTRAP
## 
## 
## Call:
## boot(data = bank_data, statistic = boot_fn_bank, R = 100)
## 
## 
## Bootstrap Statistics :
##          original        bias     std. error
## t1*  -2.416485382 -8.028300e-03 0.1255282876
## t2*  -0.346072166  6.884443e-03 0.0656667243
## t3*  -0.413788618 -1.746870e-02 0.1250063163
## t4*  -0.538843667 -2.632170e-02 0.1506685985
## t5*  -0.189089703 -1.946738e-03 0.0703688067
## t6*   0.196164320  9.726636e-03 0.1007565978
## t7*  -0.311713723  6.681341e-03 0.1118123533
## t8*  -0.236414425  4.509866e-03 0.0777245698
## t9*   0.511192792  1.878887e-02 0.0999970178
## t10* -0.173019378 -2.964749e-03 0.0639570480
## t11* -0.177429381 -1.918871e-02 0.1279365248
## t12* -0.361506746  2.929020e-02 0.2202905524
## t13*  0.203955264  3.677783e-03 0.0710370345
## t14*  0.436149134  2.678866e-03 0.0783973333
## t15*  0.269835962 -7.098522e-03 0.1134082599
## t16* -0.700007468  2.614857e-03 0.0437524671
## t17* -0.444875217  2.541731e-03 0.0564787713
## t18* -0.175980434 -1.769945e-02 0.0788122518
## t19* -1.605880094  2.710617e-03 0.0776266569
## t20* -0.763099074  2.196291e-04 0.0861235310
## t21*  0.646688881 -1.281272e-03 0.2189127383
## t22* -0.251511233 -3.810631e-03 0.0928764444
## t23* -1.163911847 -6.144847e-03 0.1196075241
## t24* -0.843156031 -4.977336e-03 0.0803586902
## t25*  0.366545869 -1.096552e-02 0.0949528655
## t26*  1.553360619  4.760479e-03 0.1289172848
## t27* -0.425837991 -2.116673e-03 0.0731852404
## t28* -0.874011401 -5.277234e-03 0.0887677215
## t29*  0.888103673  1.226003e-02 0.1220745778
## t30*  0.811484702 -3.511322e-02 0.1457014049
## t31*  0.004190172 -5.900232e-07 0.0001029556
## t32* -0.086589973 -2.098398e-03 0.0115775812
## t33*  0.233821843  1.028080e-02 0.0957398188
## t34*  2.303692088  1.141992e-02 0.0869714862
## t35* -0.078536962  3.761925e-03 0.0625711164&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;second-for-linear-regression-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Second For Linear Regression Model:&lt;/h2&gt;
&lt;div id=&#34;the-diamond-ring-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The diamond ring data&lt;/h3&gt;
&lt;p&gt;In this part we used the diamond ring data.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 440
## Columns: 9
## $ price         &amp;lt;dbl&amp;gt; 3000, 3000, 3004, 3004, 3006, 3007, 3008, 3010, 3012, 30~
## $ carat         &amp;lt;dbl&amp;gt; 0.92, 0.92, 0.82, 0.81, 0.90, 0.87, 0.80, 0.84, 0.80, 0.~
## $ colour        &amp;lt;chr&amp;gt; &amp;quot;I&amp;quot;, &amp;quot;I&amp;quot;, &amp;quot;F&amp;quot;, &amp;quot;G&amp;quot;, &amp;quot;J&amp;quot;, &amp;quot;F&amp;quot;, &amp;quot;D&amp;quot;, &amp;quot;F&amp;quot;, &amp;quot;D&amp;quot;, &amp;quot;D&amp;quot;, &amp;quot;G&amp;quot;, &amp;quot;~
## $ clarity       &amp;lt;fct&amp;gt; SI2, SI2, SI2, SI1, VS2, SI2, SI2, SI1, SI2, SI2, SI2, S~
## $ cut           &amp;lt;chr&amp;gt; &amp;quot;G&amp;quot;, &amp;quot;V&amp;quot;, &amp;quot;I&amp;quot;, &amp;quot;I&amp;quot;, &amp;quot;V&amp;quot;, &amp;quot;I&amp;quot;, &amp;quot;I&amp;quot;, &amp;quot;G&amp;quot;, &amp;quot;V&amp;quot;, &amp;quot;V&amp;quot;, &amp;quot;I&amp;quot;, &amp;quot;~
## $ certification &amp;lt;chr&amp;gt; &amp;quot;AGS&amp;quot;, &amp;quot;AGS&amp;quot;, &amp;quot;GIA&amp;quot;, &amp;quot;GIA&amp;quot;, &amp;quot;GIA&amp;quot;, &amp;quot;AGS&amp;quot;, &amp;quot;GIA&amp;quot;, &amp;quot;GIA&amp;quot;, ~
## $ polish        &amp;lt;chr&amp;gt; &amp;quot;V&amp;quot;, &amp;quot;G&amp;quot;, &amp;quot;X&amp;quot;, &amp;quot;X&amp;quot;, &amp;quot;V&amp;quot;, &amp;quot;G&amp;quot;, &amp;quot;V&amp;quot;, &amp;quot;V&amp;quot;, &amp;quot;V&amp;quot;, &amp;quot;V&amp;quot;, &amp;quot;V&amp;quot;, &amp;quot;~
## $ symmetry      &amp;lt;chr&amp;gt; &amp;quot;V&amp;quot;, &amp;quot;G&amp;quot;, &amp;quot;X&amp;quot;, &amp;quot;V&amp;quot;, &amp;quot;V&amp;quot;, &amp;quot;V&amp;quot;, &amp;quot;V&amp;quot;, &amp;quot;V&amp;quot;, &amp;quot;V&amp;quot;, &amp;quot;X&amp;quot;, &amp;quot;V&amp;quot;, &amp;quot;~
## $ wholesaler    &amp;lt;chr&amp;gt; &amp;quot;1&amp;quot;, &amp;quot;1&amp;quot;, &amp;quot;1&amp;quot;, &amp;quot;1&amp;quot;, &amp;quot;1&amp;quot;, &amp;quot;1&amp;quot;, &amp;quot;1&amp;quot;, &amp;quot;1&amp;quot;, &amp;quot;1&amp;quot;, &amp;quot;1&amp;quot;, &amp;quot;1&amp;quot;, &amp;quot;~&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;splitting-the-data-to-training-and-testing-splits-1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;splitting the data to training and testing splits&lt;/h3&gt;
&lt;p&gt;In this step we are going to split the data on hands so that 3/4 of the data would be assigned for training and 1/4 of the data would be assigned for testing.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;create-the-linear-regression-model&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;create the linear regression model&lt;/h3&gt;
&lt;p&gt;Creating the linear regression model that will be used to predict the price of the diamond ring of interest.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;creating-the-recipe-1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;creating the recipe&lt;/h3&gt;
&lt;p&gt;creating the suitable recipe to apply feature engineering to our data&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;create-workflow-1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Create workflow&lt;/h3&gt;
&lt;p&gt;Create a workflow that combine the model and the recipe.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;fit-the-model-1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Fit the model&lt;/h3&gt;
&lt;p&gt;Train and fitting the model using the training split of the data.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 36 x 5
##    term        estimate std.error statistic  p.value
##    &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;
##  1 (Intercept)    2141.     128.      16.7  2.29e-44
##  2 carat           709.      58.5     12.1  1.14e-27
##  3 colour_E       -215.      45.1     -4.75 3.13e- 6
##  4 colour_F       -280.      45.2     -6.20 1.94e- 9
##  5 colour_G       -276.      46.7     -5.91 9.47e- 9
##  6 colour_H       -343.      46.0     -7.46 9.79e-13
##  7 colour_I       -380.      46.4     -8.19 8.25e-15
##  8 colour_J       -435.      49.6     -8.76 1.65e-16
##  9 colour_K       -666.      57.1    -11.7  4.62e-26
## 10 colour_L       -878.      68.3    -12.8  2.92e-30
## # ... with 26 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;make-predictions-for-training-data-1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Make predictions for training data&lt;/h3&gt;
&lt;p&gt;Using the trained model for prediction on the training data.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 328 x 10
##    .pred price carat colour clarity cut   certification polish symmetry
##    &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;  &amp;lt;fct&amp;gt;   &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;         &amp;lt;chr&amp;gt;  &amp;lt;chr&amp;gt;   
##  1 350.    190  0.09 D      SI1     X     IGI           G      G       
##  2 134.    160  0.09 E      SI1     I     IGI           G      G       
##  3  85.6   160  0.09 F      SI1     I     IGI           V      G       
##  4 134.    180  0.09 E      SI1     I     IGI           G      G       
##  5 227.    190  0.09 E      VS1     I     IGI           V      G       
##  6 196.    330  0.1  E      VS2     V     IGI           V      G       
##  7 192.    180  0.1  E      VS2     X     IGI           G      G       
##  8  88.9   160  0.1  F      SI1     X     IGI           G      G       
##  9 142.    160  0.1  E      SI1     V     IGI           G      G       
## 10  60.7   190  0.1  E      SI2     G     IGI           V      G       
## # ... with 318 more rows, and 1 more variable: wholesaler &amp;lt;chr&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;evaluate-performance-on-tarining-data-1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Evaluate performance on tarining data&lt;/h3&gt;
&lt;p&gt;Evaluate the performance of the model on the training data.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;R-squared&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 3
##   .metric .estimator .estimate
##   &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt;
## 1 rsq     standard       0.986&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/a03-resampling-methods/index_files/figure-html/unnamed-chunk-23-1.png&#34; width=&#34;672&#34; /&gt;
&lt;em&gt;RMSE&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 3
##   .metric .estimator .estimate
##   &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt;
## 1 rmse    standard        136.&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;make-predictions-for-testing-data-1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Make predictions for testing data&lt;/h3&gt;
&lt;p&gt;Using the trained model for prediction on the testing data.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 112 x 10
##    .pred price carat colour clarity cut   certification polish symmetry
##    &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;  &amp;lt;fct&amp;gt;   &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;         &amp;lt;chr&amp;gt;  &amp;lt;chr&amp;gt;   
##  1 3035.  3000  0.92 I      SI2     G     AGS           V      V       
##  2 3028.  3000  0.92 I      SI2     V     AGS           G      G       
##  3 3088.  3006  0.9  J      VS2     V     GIA           V      V       
##  4 3027.  3027  0.81 F      SI1     V     AGS           V      V       
##  5 2957.  3036  0.81 H      SI1     V     GIA           G      V       
##  6 3235.  3041  0.83 D      SI2     G     GIA           G      G       
##  7 3052.  3044  0.91 I      SI2     I     GIA           V      V       
##  8 3000.  3062  0.8  E      SI2     V     GIA           V      V       
##  9   NA   3081  0.9  F      SI2     F     GIA           v      G       
## 10 2956.  3089  0.91 H      SI2     F     GIA           V      V       
## # ... with 102 more rows, and 1 more variable: wholesaler &amp;lt;chr&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;evaluate-performance-on-testing-data-1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Evaluate performance on testing data&lt;/h3&gt;
&lt;p&gt;Evaluate the performance of the model on the testing data.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;R-squared&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 3
##   .metric .estimator .estimate
##   &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt;
## 1 rsq     standard       0.983&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/a03-resampling-methods/index_files/figure-html/unnamed-chunk-26-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;RMSE&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 3
##   .metric .estimator .estimate
##   &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt;
## 1 rmse    standard        157.&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;apply-cross-validation-method-for-model-evaluation-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Apply Cross Validation method for model evaluation&lt;/h2&gt;
&lt;p&gt;We will use the cross-validation resampling method to evaluate the performance of our linear regression model.&lt;/p&gt;
&lt;div id=&#34;split-data-into-folds-1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Split data into folds&lt;/h3&gt;
&lt;p&gt;The train data is split-ted into 5 folds&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;fit-resamples-1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Fit resamples&lt;/h3&gt;
&lt;p&gt;Fit the folds into the workflow.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;collect-cv-metrics-1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Collect CV metrics&lt;/h3&gt;
&lt;p&gt;Show the metrics resulted from Cross-Validation process&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2 x 6
##   .metric .estimator    mean     n std_err .config             
##   &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;        &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;               
## 1 rmse    standard   153.        5 5.07    Preprocessor1_Model1
## 2 rsq     standard     0.983     5 0.00123 Preprocessor1_Model1&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion-1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;The rsq associated with the model on the training data is 0.99, that associated with the model in the testing data is 0.98 and that associated with the model using cross validation is 0.98. From that we can see that our model is performing good.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;applying-bootstrap-resampling-method-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Applying Bootstrap resampling method&lt;/h2&gt;
&lt;p&gt;In this part we are estimating the accuracy of a Linear Regression Model through the bootstrap approach which can be used to assess the variability of the coefficient estimates (Betas) and predictions from a statistical learning method.&lt;/p&gt;
&lt;p&gt;The standard error reflects the variability between the estimates we would obtain if we repeatedly took samples from the population. The standard error associated with the coefficients of both the model and that obtained through bootstrapping are shown below:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# boot_fn_rings= function (data ,index){
#   return(tidy( wkfl_rings %&amp;gt;%fit(data=data[index,]))) }

boot_fn_rings= function (data ,index ){
return (coef (lm(price ~ .,data =data , subset =index )))}

df2 &amp;lt;- model.matrix( ~ price + carat + colour + clarity+cut + certification + polish + symmetry + wholesaler-1, data = rings_data)

set.seed(103)

summary(lm(price ~ .,data =as.data.frame(df2)))$coef&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                     Estimate Std. Error     t value     Pr(&amp;gt;|t|)
## (Intercept)       -106.56155  175.79890  -0.6061560 5.447516e-01
## carat             1885.30336  133.35039  14.1379667 3.742257e-37
## colourD            895.44460   59.30734  15.0983785 3.695004e-41
## colourE            728.83798   52.92247  13.7718071 1.196791e-35
## colourF            648.29530   52.36663  12.3799311 4.580770e-30
## colourG            665.84244   51.58213  12.9083948 3.708078e-32
## colourH            595.60521   50.56202  11.7796946 9.764476e-28
## colourI            557.81920   49.66629  11.2313443 1.170879e-25
## colourJ            461.05137   49.26745   9.3581342 5.704793e-19
## colourK            199.01441   50.96007   3.9053008 1.102762e-04
## clarityI2         -590.10469   39.59374 -14.9039905 2.424038e-40
## claritySI1         652.27743   37.30949  17.4828817 2.280084e-51
## claritySI2         560.50704   30.84165  18.1737061 2.265758e-54
## claritySI3         290.45599   37.17977   7.8122046 4.902422e-14
## clarityVS1         743.08136   49.56030  14.9934784 1.020529e-40
## clarityVS2         689.49914   43.96568  15.6826658 1.246192e-43
## clarityVVS1       1015.21402  117.33428   8.6523228 1.208576e-16
## clarityVVS2        760.49537   77.07807   9.8665595 1.025130e-20
## cutG                48.81986   30.73652   1.5883339 1.129931e-01
## cutI                84.50708   30.00680   2.8162641 5.096725e-03
## cutV                78.44805   30.50328   2.5717904 1.047401e-02
## cutX                93.37420   26.51667   3.5213390 4.783374e-04
## certificationDOW  -271.24204  164.60408  -1.6478452 1.001619e-01
## certificationEGL  -307.28583   67.95169  -4.5221220 8.057030e-06
## certificationGIA    12.15763   60.44293   0.2011423 8.406885e-01
## certificationIGI  -118.26743   72.53254  -1.6305431 1.037661e-01
## polishG             66.57386   78.84945   0.8443161 3.989925e-01
## polishI            247.69579  115.61368   2.1424436 3.275488e-02
## polishv            136.45426  169.48598   0.8051065 4.212318e-01
## polishV             78.39863   81.67731   0.9598581 3.377007e-01
## polishX             84.85158   83.94039   1.0108553 3.126907e-01
## symmetryG          133.37429   42.42139   3.1440340 1.789425e-03
## symmetryV          151.49072   45.27573   3.3459583 8.967355e-04
## symmetryX          137.39985   50.44279   2.7238747 6.732040e-03
## wholesaler2        112.07125   49.94276   2.2439938 2.537367e-02
## wholesaler3      -1460.66895   78.09862 -18.7028787 1.115682e-56&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;boot(statistic = boot_fn_rings,
                  data = as.data.frame(df2), R = 1000)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## ORDINARY NONPARAMETRIC BOOTSTRAP
## 
## 
## Call:
## boot(data = as.data.frame(df2), statistic = boot_fn_rings, R = 1000)
## 
## 
## Bootstrap Statistics :
##         original      bias    std. error
## t1*   -106.56155 -9.35456333   261.67043
## t2*   1885.30336 16.89859427   177.59923
## t3*    895.44460  2.78838482    99.78342
## t4*    728.83798  1.96797173    88.88759
## t5*    648.29530  0.44403917    88.81436
## t6*    665.84244 -0.87732839    86.79063
## t7*    595.60521  1.51940839    86.22062
## t8*    557.81920  1.08977842    85.60847
## t9*    461.05137 -1.31429699    83.33705
## t10*   199.01441 -5.71033660    81.01659
## t12*  -590.10469 -5.62400852    57.95193
## t13*   652.27743  4.13415624    53.01940
## t14*   560.50704  3.28170559    46.95164
## t15*   290.45599  5.96937782    58.04980
## t16*   743.08136  5.88777718    62.79755
## t17*   689.49914  3.99395348    58.81016
## t18*  1015.21402 10.65485966    80.97264
## t19*   760.49537  4.40900611   103.99886
## t20*    48.81986 -3.96590696    42.73852
## t21*    84.50708 -2.33151751    37.91071
## t22*    78.44805 -2.30491726    32.90870
## t23*    93.37420 -1.88620077    34.89901
## t24*  -271.24204 -1.08968639    78.50134
## t25*  -307.28583 -2.51905597    53.47293
## t26*    12.15763  0.16925914    30.04501
## t27*  -118.26743  2.50044800    49.52972
## t28*    66.57386 -7.36747324   136.36556
## t29*   247.69579 -8.64360605   133.21323
## t30*   136.45426 -7.91079733   139.81229
## t31*    78.39863 -7.36281044   140.63048
## t32*    84.85158 -6.72228927   141.11272
## t33*   133.37429  0.59236148    62.87303
## t35*   151.49072 -0.05086443    65.82882
## t36*   137.39985  1.01165019    67.30974
## t37*   112.07125  0.30607925    62.57052
## t38* -1460.66895  8.51131528    99.28839
## WARNING: All values of t11* are NA
## WARNING: All values of t34* are NA&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Project </title>
      <link>/post/the-project/</link>
      <pubDate>Mon, 21 Jun 2021 00:00:00 +0000</pubDate>
      <guid>/post/the-project/</guid>
      <description>
&lt;script src=&#34;/post/the-project/index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;section-the-dataset&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The dataset&lt;/h2&gt;
&lt;p&gt;The used data set in this project composed of a record of 7 common different fish species in fish market sales. For each fish participated on this record, a certain measurements were taken, which are the fish species, the weight in Gram g, vertical length in cm, diagonal length in cm, cross length in cm, height in cm and diagonal width in cm.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;fish.png&#34; width=&#34;98%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The data was obtained from &lt;strong&gt;Kaggle &lt;/strong&gt; website, to access the source of the data use the link below&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.kaggle.com/aungpyaeap/fish-market&#34; target=&#34;_blank&#34;&gt;Link to the dataset&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;section-explanatory-data-analysis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Explanatory data analysis&lt;/h2&gt;
&lt;p&gt;In this part we are going to create a data profiling report, in this report we can get an overview of the shape and structure of our dataset by summarizing their main characters and use statistical graphics and other data visualization methods.&lt;/p&gt;
&lt;iframe height=&#34;800&#34; width=&#34;100%&#34; frameborder=&#34;no&#34; src=&#34;./report.html/&#34;&gt;
&lt;/iframe&gt;
&lt;p&gt;Based on the data profiling report, specifically in the Univariate Distribution Histogram part , We can see that there are some fishes in our data set with zero weights, we need to remove the rows where the weight equal to zero.&lt;/p&gt;
&lt;p&gt;To access the &lt;strong&gt;Data Profiling Report&lt;/strong&gt; in a new window please press the link below
&lt;a href=&#34;./report.html&#34; target=&#34;_blank&#34;&gt;Link to open the data profiling report in a new window&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In this part we can interactively perform further exploration to our data set.&lt;/p&gt;
&lt;iframe height=&#34;1000&#34; width=&#34;100%&#34; frameborder=&#34;no&#34; src=&#34;https://nouran.shinyapps.io/2021-06-21-project/&#34;&gt;
&lt;/iframe&gt;
&lt;p&gt;To open the &lt;strong&gt;Shiny app&lt;/strong&gt; in a new window please press the link below
&lt;a href=&#34;https://nouran.shinyapps.io/2021-06-21-project/&#34; target=&#34;_blank&#34;&gt;Link to open the Shiny app in a new window&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;section-fitting-a-model-to-predict-the-fish-height-based-on-its-cross-length&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Fitting a model to predict the fish height based on it’s cross length&lt;/h1&gt;
&lt;div id=&#34;section-linear-regression-model&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Linear Regression Model&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;To create a liner regression model to predict the height of a fish given its cross length, we need to determine the value of &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; that is the population parameter for the intercept and the value of &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; that is the population parameter for the slope as shown in the following model:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\widehat{Height}_{i} = \beta_0 + \beta_1 \times Cross Length_{i}\]&lt;/span&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;After determining the values of both &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt;, the updated linear regression model with the values of &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; is shown as follow:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\widehat{Height}_{i} = 0.87 + 0.26 \times Cross Length_{i}\]&lt;/span&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;From the above model we can see that :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Slope: For each additional cm the fish is longer, the height is expected to be higher, on average, by 0.26 cm.&lt;/li&gt;
&lt;li&gt;Intercept: fish that is 8.8 cm tall (minimum cross length value among the dataset) is expected to be 3.2 cm high, on average.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;section-the-data-is-shown-in-the-following-plot&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The data is shown in the following plot:&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;/post/the-project/index_files/figure-html/height-cross_length-plot-1.png&#34; width=&#34;100%&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;section-the-data-and-the-least-square-line-are-shown-in-the-following-plot&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The data and the least square line are shown in the following plot:&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;/post/the-project/index_files/figure-html/heightcross_length-plot-1.png&#34; width=&#34;100%&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;section-the-data-the-least-square-line-and-the-residuales-are-shown-in-the-following-plot&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The data, the least square line and the residuales are shown in the following plot:&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;/post/the-project/index_files/figure-html/vis-res-1-1.png&#34; width=&#34;100%&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Fitting and Interpreting models </title>
      <link>/post/fitting-and-interpreting-models/</link>
      <pubDate>Tue, 15 Jun 2021 00:00:00 +0000</pubDate>
      <guid>/post/fitting-and-interpreting-models/</guid>
      <description>
&lt;script src=&#34;/post/fitting-and-interpreting-models/index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/post/fitting-and-interpreting-models/index_files/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;/post/fitting-and-interpreting-models/index_files/lightable/lightable.css&#34; rel=&#34;stylesheet&#34; /&gt;


&lt;div id=&#34;import-libraries&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Import Libraries&lt;/h2&gt;
&lt;/div&gt;
&lt;div id=&#34;import-data-paris-paintings&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Import Data: Paris Paintings&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pp &amp;lt;- read_csv(&amp;quot;paris-paintings.csv&amp;quot;, na = c(&amp;quot;n/a&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;NA&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## -- Column specification --------------------------------------------------------
## cols(
##   .default = col_double(),
##   name = col_character(),
##   sale = col_character(),
##   lot = col_character(),
##   dealer = col_character(),
##   origin_author = col_character(),
##   origin_cat = col_character(),
##   school_pntg = col_character(),
##   price = col_number(),
##   subject = col_character(),
##   authorstandard = col_character(),
##   authorstyle = col_character(),
##   author = col_character(),
##   winningbidder = col_character(),
##   winningbiddertype = col_character(),
##   endbuyer = col_character(),
##   type_intermed = col_character(),
##   Shape = col_character(),
##   material = col_character(),
##   mat = col_character(),
##   materialCat = col_character()
## )
## i Use `spec()` for the full column specifications.&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;goal-predict-height-from-width&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Goal: Predict height from width&lt;/h2&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\widehat{height}_{i} = \beta_0 + \beta_1 \times width_{i}\]&lt;/span&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using formula &amp;#39;y ~ x&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/fitting-and-interpreting-models/index_files/figure-html/height-width-plot-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;img src=&#34;tidymodels.png&#34; width=&#34;98%&#34; /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;step-1-specify-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 1: Specify model&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;linear_reg()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Linear Regression Model Specification (regression)&lt;/code&gt;&lt;/pre&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;step-2-set-model-fitting-engine&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 2: Set model fitting &lt;em&gt;engine&lt;/em&gt;&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;linear_reg() %&amp;gt;%
  set_engine(&amp;quot;lm&amp;quot;) # lm: linear model&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Linear Regression Model Specification (regression)
## 
## Computational engine: lm&lt;/code&gt;&lt;/pre&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;step-3-fit-model-estimate-parameters&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 3: Fit model &amp;amp; estimate parameters&lt;/h2&gt;
&lt;p&gt;… using &lt;strong&gt;formula syntax&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;linear_reg() %&amp;gt;%
  set_engine(&amp;quot;lm&amp;quot;) %&amp;gt;%
  fit(Height_in ~ Width_in, data = pp)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## parsnip model object
## 
## Fit time:  0ms 
## 
## Call:
## stats::lm(formula = Height_in ~ Width_in, data = data)
## 
## Coefficients:
## (Intercept)     Width_in  
##      3.6214       0.7808&lt;/code&gt;&lt;/pre&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;a-closer-look-at-model-output&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;A closer look at model output&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;## parsnip model object
## 
## Fit time:  0ms 
## 
## Call:
## stats::lm(formula = Height_in ~ Width_in, data = data)
## 
## Coefficients:
## (Intercept)     Width_in  
##      3.6214       0.7808&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;.large[
&lt;span class=&#34;math display&#34;&gt;\[\widehat{height}_{i} = 3.6214 + 0.7808 \times width_{i}\]&lt;/span&gt;]&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;a-tidy-look-at-model-output&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;A tidy look at model output&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;linear_reg() %&amp;gt;%
  set_engine(&amp;quot;lm&amp;quot;) %&amp;gt;%
  fit(Height_in ~ Width_in, data = pp) %&amp;gt;%
  tidy()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2 x 5
##   term        estimate std.error statistic  p.value
##   &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;
## 1 (Intercept)    3.62    0.254        14.3 8.82e-45
## 2 Width_in       0.781   0.00950      82.1 0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;.large[
&lt;span class=&#34;math display&#34;&gt;\[\widehat{height}_{i} = 3.62 + 0.781 \times width_{i}\]&lt;/span&gt;]&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;slope-and-intercept&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Slope and intercept&lt;/h2&gt;
&lt;p&gt;.large[
&lt;span class=&#34;math display&#34;&gt;\[\widehat{height}_{i} = 3.62 + 0.781 \times width_{i}\]&lt;/span&gt;]&lt;/p&gt;
&lt;p&gt;–&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Slope:&lt;/strong&gt; For each additional inch the painting is wider, the height is expected to be higher, on average, by 0.781 inches.&lt;/li&gt;
&lt;/ul&gt;
&lt;table style=&#34;width:4%;&#34;&gt;
&lt;colgroup&gt;
&lt;col width=&#34;4%&#34; /&gt;
&lt;/colgroup&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;- &lt;strong&gt;Intercept:&lt;/strong&gt; Paintings that are 0 inches wide are expected to be 3.62 inches high, on average. (Does this make sense?)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;correlation-does-not-imply-causation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Correlation does not imply causation&lt;/h2&gt;
&lt;p&gt;Remember this when interpreting model coefficients&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;cell_phones.png&#34; width=&#34;90%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;.footnote[
Source: XKCD, &lt;a href=&#34;https://xkcd.com/925/&#34;&gt;Cell phones&lt;/a&gt;]&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;class: middle&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;parameter-estimation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Parameter estimation&lt;/h1&gt;
&lt;hr /&gt;
&lt;div id=&#34;linear-model-with-a-single-predictor&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Linear model with a single predictor&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;We’re interested in &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; (population parameter for the intercept) and &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; (population parameter for the slope) in the following model:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\hat{y}_{i} = \beta_0 + \beta_1~x_{i}\]&lt;/span&gt;&lt;/p&gt;
&lt;table style=&#34;width:4%;&#34;&gt;
&lt;colgroup&gt;
&lt;col width=&#34;4%&#34; /&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;- Tough luck, you can’t have them…&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;- So we use sample statistics to estimate them:&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;&lt;span class=&#34;math display&#34;&gt;\[\hat{y}_{i} = b_0 + b_1~x_{i}\]&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;least-squares-regression&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Least squares regression&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;The regression line minimizes the sum of squared residuals.&lt;/li&gt;
&lt;/ul&gt;
&lt;table style=&#34;width:4%;&#34;&gt;
&lt;colgroup&gt;
&lt;col width=&#34;4%&#34; /&gt;
&lt;/colgroup&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;- If &lt;span class=&#34;math inline&#34;&gt;\(e_i = y_i - \hat{y}_i\)&lt;/span&gt;, then, the regression line minimizes
&lt;span class=&#34;math inline&#34;&gt;\(\sum_{i = 1}^n e_i^2\)&lt;/span&gt;.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;visualizing-residuals&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Visualizing residuals&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;/post/fitting-and-interpreting-models/index_files/figure-html/vis-res-1-1.png&#34; width=&#34;70%&#34; /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;visualizing-residuals-cont.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Visualizing residuals (cont.)&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using formula &amp;#39;y ~ x&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/fitting-and-interpreting-models/index_files/figure-html/vis-res-2-1.png&#34; width=&#34;70%&#34; /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;visualizing-residuals-cont.-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Visualizing residuals (cont.)&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using formula &amp;#39;y ~ x&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/fitting-and-interpreting-models/index_files/figure-html/vis-res-3-1.png&#34; width=&#34;70%&#34; /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;properties-of-least-squares-regression&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Properties of least squares regression&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;The regression line goes through the center of mass point, the coordinates corresponding to average &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; and average &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\((\bar{x}, \bar{y})\)&lt;/span&gt;:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\bar{y} = b_0 + b_1 \bar{x} ~ \rightarrow ~ b_0 = \bar{y} - b_1 \bar{x}\]&lt;/span&gt;&lt;/p&gt;
&lt;table style=&#34;width:4%;&#34;&gt;
&lt;colgroup&gt;
&lt;col width=&#34;4%&#34; /&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;- The slope has the same sign as the correlation coefficient: &lt;span class=&#34;math inline&#34;&gt;\(b_1 = r \frac{s_y}{s_x}\)&lt;/span&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;- The sum of the residuals is zero: &lt;span class=&#34;math inline&#34;&gt;\(\sum_{i = 1}^n e_i = 0\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;The residuals and &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; values are uncorrelated&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;p&gt;class: middle&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;models-with-categorical-explanatory-variables&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Models with categorical explanatory variables&lt;/h1&gt;
&lt;hr /&gt;
&lt;div id=&#34;categorical-predictor-with-2-levels&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Categorical predictor with 2 levels&lt;/h2&gt;
&lt;p&gt;.pull-left-narrow[
.small[&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3,393 x 3
##    name      Height_in landsALL
##    &amp;lt;chr&amp;gt;         &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;
##  1 L1764-2          37        0
##  2 L1764-3          18        0
##  3 L1764-4          13        1
##  4 L1764-5a         14        1
##  5 L1764-5b         14        1
##  6 L1764-6           7        0
##  7 L1764-7a          6        0
##  8 L1764-7b          6        0
##  9 L1764-8          15        0
## 10 L1764-9a          9        0
## 11 L1764-9b          9        0
## 12 L1764-10a        16        1
## 13 L1764-10b        16        1
## 14 L1764-10c        16        1
## 15 L1764-11         20        0
## 16 L1764-12a        14        1
## 17 L1764-12b        14        1
## 18 L1764-13a        15        1
## 19 L1764-13b        15        1
## 20 L1764-14         37        0
## # ... with 3,373 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;]
]
.pull-right-wide[
- &lt;code&gt;landsALL = 0&lt;/code&gt;: No landscape features
- &lt;code&gt;landsALL = 1&lt;/code&gt;: Some landscape features]&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;height-landscape-features&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Height &amp;amp; landscape features&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;linear_reg() %&amp;gt;%
  set_engine(&amp;quot;lm&amp;quot;) %&amp;gt;%
  fit(Height_in ~ factor(landsALL), data = pp) %&amp;gt;%
  tidy()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2 x 5
##   term              estimate std.error statistic  p.value
##   &amp;lt;chr&amp;gt;                &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;
## 1 (Intercept)          22.7      0.328      69.1 0       
## 2 factor(landsALL)1    -5.65     0.532     -10.6 7.97e-26&lt;/code&gt;&lt;/pre&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;height-landscape-features-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Height &amp;amp; landscape features&lt;/h2&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\widehat{Height_{in}} = 22.7 - 5.645~landsALL\]&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Slope:&lt;/strong&gt; Paintings with landscape features are expected, on average, to be 5.645 inches shorter than paintings that without landscape features
&lt;ul&gt;
&lt;li&gt;Compares baseline level (&lt;code&gt;landsALL = 0&lt;/code&gt;) to the other level (&lt;code&gt;landsALL = 1&lt;/code&gt;)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Intercept:&lt;/strong&gt; Paintings that don’t have landscape features are expected, on average, to be 22.7 inches tall&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;relationship-between-height-and-school&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Relationship between height and school&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;linear_reg() %&amp;gt;%
  set_engine(&amp;quot;lm&amp;quot;) %&amp;gt;%
  fit(Height_in ~ school_pntg, data = pp) %&amp;gt;%
  tidy()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 7 x 5
##   term            estimate std.error statistic p.value
##   &amp;lt;chr&amp;gt;              &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;
## 1 (Intercept)        14.0       10.0     1.40  0.162  
## 2 school_pntgD/FL     2.33      10.0     0.232 0.816  
## 3 school_pntgF       10.2       10.0     1.02  0.309  
## 4 school_pntgG        1.65      11.9     0.139 0.889  
## 5 school_pntgI       10.3       10.0     1.02  0.306  
## 6 school_pntgS       30.4       11.4     2.68  0.00744
## 7 school_pntgX        2.87      10.3     0.279 0.780&lt;/code&gt;&lt;/pre&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;dummy-variables&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Dummy variables&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 7 x 5
##   term            estimate std.error statistic p.value
##   &amp;lt;chr&amp;gt;              &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;
## 1 (Intercept)        14.0       10.0     1.40  0.162  
## 2 school_pntgD/FL     2.33      10.0     0.232 0.816  
## 3 school_pntgF       10.2       10.0     1.02  0.309  
## 4 school_pntgG        1.65      11.9     0.139 0.889  
## 5 school_pntgI       10.3       10.0     1.02  0.306  
## 6 school_pntgS       30.4       11.4     2.68  0.00744
## 7 school_pntgX        2.87      10.3     0.279 0.780&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;When the categorical explanatory variable has many levels, they’re encoded to &lt;strong&gt;dummy variables&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Each coefficient describes the expected difference between heights in that particular school compared to the baseline level&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;categorical-predictor-with-3-levels&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Categorical predictor with 3+ levels&lt;/h2&gt;
.pull-left-wide[
&lt;table class=&#34;table&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
school_pntg
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
D_FL
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
F
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
G
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
I
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
S
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
X
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
A
&lt;/td&gt;
&lt;td style=&#34;text-align:center;width: 10em; color: white !important;background-color: rgba(68, 1, 84, 1) !important;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;width: 10em; color: white !important;background-color: rgba(68, 1, 84, 1) !important;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;width: 10em; color: white !important;background-color: rgba(68, 1, 84, 1) !important;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;width: 10em; color: white !important;background-color: rgba(68, 1, 84, 1) !important;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;width: 10em; color: white !important;background-color: rgba(68, 1, 84, 1) !important;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;width: 10em; color: white !important;background-color: rgba(68, 1, 84, 1) !important;&#34;&gt;
0
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
D/FL
&lt;/td&gt;
&lt;td style=&#34;text-align:center;width: 10em; color: white !important;background-color: rgba(122, 209, 81, 1) !important;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;width: 10em; color: white !important;background-color: rgba(68, 1, 84, 1) !important;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;width: 10em; color: white !important;background-color: rgba(68, 1, 84, 1) !important;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;width: 10em; color: white !important;background-color: rgba(68, 1, 84, 1) !important;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;width: 10em; color: white !important;background-color: rgba(68, 1, 84, 1) !important;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;width: 10em; color: white !important;background-color: rgba(68, 1, 84, 1) !important;&#34;&gt;
0
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
F
&lt;/td&gt;
&lt;td style=&#34;text-align:center;width: 10em; color: white !important;background-color: rgba(68, 1, 84, 1) !important;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;width: 10em; color: white !important;background-color: rgba(122, 209, 81, 1) !important;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;width: 10em; color: white !important;background-color: rgba(68, 1, 84, 1) !important;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;width: 10em; color: white !important;background-color: rgba(68, 1, 84, 1) !important;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;width: 10em; color: white !important;background-color: rgba(68, 1, 84, 1) !important;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;width: 10em; color: white !important;background-color: rgba(68, 1, 84, 1) !important;&#34;&gt;
0
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
G
&lt;/td&gt;
&lt;td style=&#34;text-align:center;width: 10em; color: white !important;background-color: rgba(68, 1, 84, 1) !important;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;width: 10em; color: white !important;background-color: rgba(68, 1, 84, 1) !important;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;width: 10em; color: white !important;background-color: rgba(122, 209, 81, 1) !important;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;width: 10em; color: white !important;background-color: rgba(68, 1, 84, 1) !important;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;width: 10em; color: white !important;background-color: rgba(68, 1, 84, 1) !important;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;width: 10em; color: white !important;background-color: rgba(68, 1, 84, 1) !important;&#34;&gt;
0
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
I
&lt;/td&gt;
&lt;td style=&#34;text-align:center;width: 10em; color: white !important;background-color: rgba(68, 1, 84, 1) !important;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;width: 10em; color: white !important;background-color: rgba(68, 1, 84, 1) !important;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;width: 10em; color: white !important;background-color: rgba(68, 1, 84, 1) !important;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;width: 10em; color: white !important;background-color: rgba(122, 209, 81, 1) !important;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;width: 10em; color: white !important;background-color: rgba(68, 1, 84, 1) !important;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;width: 10em; color: white !important;background-color: rgba(68, 1, 84, 1) !important;&#34;&gt;
0
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
S
&lt;/td&gt;
&lt;td style=&#34;text-align:center;width: 10em; color: white !important;background-color: rgba(68, 1, 84, 1) !important;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;width: 10em; color: white !important;background-color: rgba(68, 1, 84, 1) !important;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;width: 10em; color: white !important;background-color: rgba(68, 1, 84, 1) !important;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;width: 10em; color: white !important;background-color: rgba(68, 1, 84, 1) !important;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;width: 10em; color: white !important;background-color: rgba(122, 209, 81, 1) !important;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;width: 10em; color: white !important;background-color: rgba(68, 1, 84, 1) !important;&#34;&gt;
0
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
X
&lt;/td&gt;
&lt;td style=&#34;text-align:center;width: 10em; color: white !important;background-color: rgba(68, 1, 84, 1) !important;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;width: 10em; color: white !important;background-color: rgba(68, 1, 84, 1) !important;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;width: 10em; color: white !important;background-color: rgba(68, 1, 84, 1) !important;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;width: 10em; color: white !important;background-color: rgba(68, 1, 84, 1) !important;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;width: 10em; color: white !important;background-color: rgba(68, 1, 84, 1) !important;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;width: 10em; color: white !important;background-color: rgba(122, 209, 81, 1) !important;&#34;&gt;
1
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;]
.pull-right-narrow[
.small[&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3,393 x 3
##    name      Height_in school_pntg
##    &amp;lt;chr&amp;gt;         &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;      
##  1 L1764-2          37 F          
##  2 L1764-3          18 I          
##  3 L1764-4          13 D/FL       
##  4 L1764-5a         14 F          
##  5 L1764-5b         14 F          
##  6 L1764-6           7 I          
##  7 L1764-7a          6 F          
##  8 L1764-7b          6 F          
##  9 L1764-8          15 I          
## 10 L1764-9a          9 D/FL       
## 11 L1764-9b          9 D/FL       
## 12 L1764-10a        16 X          
## 13 L1764-10b        16 X          
## 14 L1764-10c        16 X          
## 15 L1764-11         20 D/FL       
## 16 L1764-12a        14 D/FL       
## 17 L1764-12b        14 D/FL       
## 18 L1764-13a        15 D/FL       
## 19 L1764-13b        15 D/FL       
## 20 L1764-14         37 F          
## # ... with 3,373 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;]
]&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;relationship-between-height-and-school-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Relationship between height and school&lt;/h2&gt;
&lt;p&gt;.small[&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 7 x 5
##   term            estimate std.error statistic p.value
##   &amp;lt;chr&amp;gt;              &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;
## 1 (Intercept)        14.0       10.0     1.40  0.162  
## 2 school_pntgD/FL     2.33      10.0     0.232 0.816  
## 3 school_pntgF       10.2       10.0     1.02  0.309  
## 4 school_pntgG        1.65      11.9     0.139 0.889  
## 5 school_pntgI       10.3       10.0     1.02  0.306  
## 6 school_pntgS       30.4       11.4     2.68  0.00744
## 7 school_pntgX        2.87      10.3     0.279 0.780&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Austrian school (A)&lt;/strong&gt; paintings are expected, on average, to be &lt;strong&gt;14 inches&lt;/strong&gt; tall.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Dutch/Flemish school (D/FL)&lt;/strong&gt; paintings are expected, on average, to be &lt;strong&gt;2.33 inches taller&lt;/strong&gt; than &lt;em&gt;Austrian school&lt;/em&gt; paintings.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;French school (F)&lt;/strong&gt; paintings are expected, on average, to be &lt;strong&gt;10.2 inches taller&lt;/strong&gt; than &lt;em&gt;Austrian school&lt;/em&gt; paintings.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;German school (G)&lt;/strong&gt; paintings are expected, on average, to be &lt;strong&gt;1.65 inches taller&lt;/strong&gt; than &lt;em&gt;Austrian school&lt;/em&gt; paintings.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Italian school (I)&lt;/strong&gt; paintings are expected, on average, to be &lt;strong&gt;10.3 inches taller&lt;/strong&gt; than &lt;em&gt;Austrian school&lt;/em&gt; paintings.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Spanish school (S)&lt;/strong&gt; paintings are expected, on average, to be &lt;strong&gt;30.4 inches taller&lt;/strong&gt; than &lt;em&gt;Austrian school&lt;/em&gt; paintings.&lt;/li&gt;
&lt;li&gt;Paintings whose school is &lt;strong&gt;unknown (X)&lt;/strong&gt; are expected, on average, to be &lt;strong&gt;2.87 inches taller&lt;/strong&gt; than &lt;em&gt;Austrian school&lt;/em&gt; paintings.
]&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
